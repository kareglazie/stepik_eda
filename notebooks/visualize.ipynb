{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d84a3aad",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22470cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import string\n",
    "from umap import UMAP\n",
    "import json\n",
    "\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21ae8ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/stepik_parsed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee13058",
   "metadata": {},
   "source": [
    "### Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3753a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Гистограмма без выбросов\n",
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "main_data = df[df['price'] <= upper_bound]\n",
    "\n",
    "fig = px.histogram(\n",
    "    main_data,\n",
    "    x='price',\n",
    "    nbins=50,\n",
    "    title=f'<b>Распределение цен на курсы (без выбросов)</b><br><sub>Граница выбросов: {int(upper_bound)} руб. | Всего курсов: {len(main_data)}</sub>',\n",
    "    labels={'price': 'Цена (рубли)', 'count': 'Количество курсов'},\n",
    "    color_discrete_sequence=['#29b6f6'],\n",
    "    opacity=0.85,\n",
    "    marginal=None, \n",
    "    width=1000,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    hovermode='x unified',\n",
    "    xaxis_title_font=dict(size=14),\n",
    "    yaxis_title_font=dict(size=14),\n",
    "    title_font=dict(size=18),\n",
    "    template='plotly_white',\n",
    "    bargap=0.1,\n",
    "    showlegend=False,\n",
    "    annotations=[\n",
    "        dict(\n",
    "            x=0.95,\n",
    "            y=0.95,\n",
    "            xref='paper',\n",
    "            yref='paper',\n",
    "            text=f\"<b>Статистика:</b><br>Медиана: {main_data['price'].median():.0f} руб.<br>Среднее: {main_data['price'].mean():.0f} руб.\",\n",
    "            showarrow=False,\n",
    "            align='left',\n",
    "            bordercolor='black',\n",
    "            borderwidth=1,\n",
    "            borderpad=4,\n",
    "            bgcolor='white'\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    hovertemplate=\"<b>Диапазон:</b> %{x} руб.<br><b>Количество курсов:</b> %{y}\",\n",
    "    marker_line_width=1,\n",
    "    marker_line_color='white'\n",
    ")\n",
    "\n",
    "for price, name, color in [\n",
    "    (main_data['price'].median(), 'Медиана', '#ff7043'),\n",
    "    (main_data['price'].mean(), 'Среднее', '#66bb6a')\n",
    "]:\n",
    "    fig.add_vline(\n",
    "        x=price,\n",
    "        line_dash=\"dash\",\n",
    "        line_color=color,\n",
    "        annotation_text=name,\n",
    "        annotation_position=\"top\",\n",
    "        annotation_font_color=color\n",
    "    )\n",
    "\n",
    "fig.write_html(\n",
    "    \"../plots/price_distribution_main.html\",\n",
    "    auto_play=False,\n",
    "    include_plotlyjs='cdn'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0cf2ec",
   "metadata": {},
   "source": [
    "### Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6090f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "top20 = df.sort_values('students', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4009ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=top20, y='title', x='students')\n",
    "plt.title('Топ-20 курсов по количеству студентов', pad=20)\n",
    "plt.xlabel('Количество студентов')\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.grid(True, linestyle=':', linewidth=0.6)\n",
    "plt.savefig('../plots/top20_popular.png', dpi=120, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80204c8",
   "metadata": {},
   "source": [
    "### Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d86b9b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "russian_stopwords = set(stopwords.words('russian'))\n",
    "\n",
    "custom_stopwords = {\n",
    "    'курс', 'курса', 'курсе', 'курсов', 'научитесь', 'научиться', \n",
    "    'изучение', 'изучить', 'будете', 'можно', 'весь', 'свой',\n",
    "    'вас', 'вам', 'это', 'этого', 'которые', 'который', \"также\",\n",
    "    \"основы\", \"также\", \"языка\", \"язык\", \"основы\", \"позволит\", \"ещё\",\n",
    "    \"содержит\", \"изучения\", \"всего\", \"всему\", \"всем\", \"своего\",\n",
    "    \"своему\", \"своим\", \"своем\", \"своя\", \"своей\", \"свою\", \"свое\",\n",
    "    \"этому\", \"этот\", \"этим\", \"эта\", \"жту\", \"этой\", \"эти\", \"этим\",\n",
    "    \"этими\", \"этих\", \"которых\", \"которыми\", \"которого\", \"которому\",\n",
    "    \"которым\", \"котором\", \"которая\", \"которую\", \"которой\", \"которых\",\n",
    "    \"которым\", \"которыми\", \"которое\", \"вы\", \"тех\", \"хочет\", \"кто\", \"еще\",\n",
    "    \"поможет\", \"узнаете\", \"предназначен\", \"языку\", \"свои\", \"посвящен\",\n",
    "    \"начать\", \"часть\", \"заданий\", \"самых\", \"каждый\", \"помощью\", \"языке\",\n",
    "    \"чему\", \"сможете\", \"понимать\", \"создавать\", \"изучите\", \"stepik\"\n",
    "}\n",
    "\n",
    "all_stopwords = set(stopwords.words('russian')).union(custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62ac44ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# с Tf-Idf\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=150,\n",
    "    stop_words=list(all_stopwords),\n",
    "    preprocessor=lambda x: ''.join([c for c in x.lower() if c not in string.punctuation and not c.isdigit()])\n",
    ")\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(df['title'] + ' ' + df['about'])\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "mean_tfidf = tfidf_matrix.mean(axis=0).A1\n",
    "word_weights = dict(zip(feature_names, mean_tfidf))\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='black',\n",
    "    colormap='viridis',\n",
    "    contour_width=1,\n",
    "    contour_color='steelblue'\n",
    ").generate_from_frequencies(word_weights)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../plots/wordcloud_tfidf.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72494ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# без Tf-Idf\n",
    "text = ' '.join(df['title'] + ' ' + df['about'])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = ''.join([char for char in text if char not in string.punctuation and not char.isdigit()])\n",
    "    words = text.lower().split()\n",
    "    return [word for word in words if word not in all_stopwords and len(word) > 2]\n",
    "\n",
    "words = preprocess_text(text)\n",
    "word_freq = Counter(words)\n",
    "\n",
    "for common_word in [w for w, _ in word_freq.most_common(8)]:\n",
    "    del word_freq[common_word]\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='black',\n",
    "    stopwords=all_stopwords,\n",
    "    colormap='viridis',\n",
    "    max_words=150,\n",
    "    contour_width=1,\n",
    "    contour_color='steelblue'\n",
    ").generate_from_frequencies(word_freq)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../plots/wordcloud_filtered.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a7c0a7",
   "metadata": {},
   "source": [
    "### Clusterization (K-Means) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8fcfbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('Alibaba-NLP/gte-multilingual-base', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d556778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined_text'] = df.apply(lambda x: ' '.join(filter(None, [str(x['title']), str(x['about']), str(x['skills'])])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ee62917",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(df['combined_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe9681f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_optimal_clusters(embeddings, max_k=15):\n",
    "    elbow_visualizer = KElbowVisualizer(\n",
    "        KMeans(random_state=42),\n",
    "        k=(2, max_k),\n",
    "        metric='distortion',\n",
    "        timings=False\n",
    "    )\n",
    "    plt.grid(True, linestyle=':', linewidth=0.6)\n",
    "    elbow_visualizer.fit(embeddings)\n",
    "    elbow_k = elbow_visualizer.elbow_value_\n",
    "    elbow_visualizer.show(outpath=\"../plots/elbow_method.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    silhouette_scores = []\n",
    "    k_values = range(2, max_k+1)\n",
    "    \n",
    "    for k in k_values:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(embeddings)\n",
    "        silhouette_scores.append(silhouette_score(embeddings, labels))\n",
    "    \n",
    "    best_silhouette_k = k_values[np.argmax(silhouette_scores)]\n",
    "    best_silhouette_score = max(silhouette_scores)\n",
    "    \n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(k_values, silhouette_scores, 'bo-')\n",
    "    plt.grid(True, linestyle=':', linewidth=0.6)\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.title('Silhouette Analysis for Optimal k')\n",
    "    plt.axvline(x=best_silhouette_k, color='r', linestyle='--')\n",
    "    plt.text(best_silhouette_k+0.5, 0.1, \n",
    "             f'Optimal k={best_silhouette_k} (score={best_silhouette_score:.3f})', \n",
    "             color='red')\n",
    "    plt.savefig(\"../plots/silhouette_analysis.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    if elbow_k != best_silhouette_k:\n",
    "        final_k = int(np.round((elbow_k + best_silhouette_k)/2))\n",
    "        print(f\"Метод локтя предложил k={elbow_k}, silhouette - k={best_silhouette_k}\")\n",
    "        print(f\"Компромиссное значение: k={final_k}\")\n",
    "    else:\n",
    "        final_k = elbow_k\n",
    "    \n",
    "    explanation = f\"\"\"\n",
    "    #### Обоснование выбора числа кластеров (k={final_k})\n",
    "\n",
    "    ##### 1. Метод локтя\n",
    "    На графике наблюдается изгиб при k={elbow_k}.\n",
    "\n",
    "    ##### 2. Silhouette Score\n",
    "    Максимальное значение silhouette score ({best_silhouette_score:.3f}) достигается при k={best_silhouette_k}.\n",
    "\n",
    "    ##### 3. Согласование результатов\n",
    "    - Метод локтя: k={elbow_k}\n",
    "    - Silhouette: k={best_silhouette_k}\n",
    "    - **Выбранное значение**: k={final_k} (среднее округленное)\n",
    "    \"\"\"\n",
    "\n",
    "    with open(\"../plots/cluster_choice_explanation.md\", \"w\") as f:\n",
    "        f.write(explanation)\n",
    "    \n",
    "    return final_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6cd31cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод локтя предложил k=9, silhouette - k=14\n",
      "Компромиссное значение: k=12\n"
     ]
    }
   ],
   "source": [
    "optimal_k = determine_optimal_clusters(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "667ed81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score для k=12: 0.055\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(embeddings)\n",
    "\n",
    "final_score = silhouette_score(embeddings, df['cluster'])\n",
    "print(f\"Silhouette Score для k={optimal_k}: {final_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c273a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/stepik_analyzed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6195fd54",
   "metadata": {},
   "source": [
    "### UMAP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b40a4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/stepik_analyzed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e5740f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_3d = UMAP(\n",
    "    n_components=3,\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    metric='cosine'\n",
    ")\n",
    "umap_3d_embeds = umap_3d.fit_transform(embeddings)\n",
    "\n",
    "df[['x', 'y', 'z']] = umap_3d_embeds\n",
    "\n",
    "cluster_colors = px.colors.qualitative.Plotly\n",
    "\n",
    "fig_3d = go.Figure()\n",
    "\n",
    "for cluster in sorted(df['cluster'].unique()):\n",
    "    cluster_df = df[df['cluster'] == cluster]\n",
    "    fig_3d.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=cluster_df['x'],\n",
    "            y=cluster_df['y'],\n",
    "            z=cluster_df['z'],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=7,\n",
    "                color=cluster_colors[cluster % len(cluster_colors)],\n",
    "                opacity=0.9,\n",
    "                line=dict(width=1.5, color='#333') \n",
    "            ),\n",
    "            name=f'Кластер {cluster}',\n",
    "            hovertext=cluster_df.apply(\n",
    "                lambda row: f\"{row['title']}<br>Цена: {row['price']} руб<br>Студентов: {row['students']:,}\",\n",
    "                axis=1\n",
    "            ),\n",
    "            hoverinfo='text'\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig_3d.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='Ось X',\n",
    "        yaxis_title='Ось Y',\n",
    "        zaxis_title='Ось Z',\n",
    "        xaxis=dict(\n",
    "            backgroundcolor='rgba(240,240,240,0.5)',\n",
    "            gridcolor='black', \n",
    "            gridwidth=2,       \n",
    "            showbackground=True,\n",
    "            linecolor='black', \n",
    "            linewidth=3        \n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            backgroundcolor='rgba(240,240,240,0.5)',\n",
    "            gridcolor='black',\n",
    "            gridwidth=2,\n",
    "            showbackground=True,\n",
    "            linecolor='black',\n",
    "            linewidth=3\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            backgroundcolor='rgba(240,240,240,0.5)',\n",
    "            gridcolor='black',\n",
    "            gridwidth=2,\n",
    "            showbackground=True,\n",
    "            linecolor='black',\n",
    "            linewidth=3\n",
    "        ),\n",
    "        camera=dict(\n",
    "            up=dict(x=0, y=0, z=1),\n",
    "            center=dict(x=0, y=0, z=0),\n",
    "            eye=dict(x=1.5, y=1.5, z=0.6)\n",
    "        ),\n",
    "        bgcolor='white' \n",
    "    ),\n",
    "    width=1100,\n",
    "    height=700,\n",
    "    legend=dict(\n",
    "        title=dict(text='<b>Кластеры</b>', font=dict(size=14)),\n",
    "        itemsizing='constant',\n",
    "        font=dict(size=12)\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=50),\n",
    "    paper_bgcolor='white',\n",
    "    font=dict(family=\"Arial\", color=\"black\")\n",
    ")\n",
    "\n",
    "fig_3d.update_traces(\n",
    "    marker=dict(\n",
    "        sizemode='diameter',\n",
    "        sizeref=0.1,\n",
    "        symbol='circle'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig_3d.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            buttons=[\n",
    "                dict(\n",
    "                    label=\"Сброс\",\n",
    "                    method=\"relayout\",\n",
    "                    args=[\"scene.camera\", dict(\n",
    "                        up=dict(x=0, y=0, z=1),\n",
    "                        center=dict(x=0, y=0, z=0),\n",
    "                        eye=dict(x=1.5, y=1.5, z=0.6)\n",
    "                    )]\n",
    "                )\n",
    "            ],\n",
    "            direction=\"left\",\n",
    "            pad={\"r\": 10, \"t\": 10},\n",
    "            showactive=False,\n",
    "            x=0.05,\n",
    "            xanchor=\"left\",\n",
    "            y=0,\n",
    "            yanchor=\"top\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig_3d.write_html(\"../plots/umap_3d_visualization.html\", include_plotlyjs='cdn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdec966",
   "metadata": {},
   "source": [
    "### Word Cloud for Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "606bf616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=100, stop_words=list(all_stopwords))\n",
    "tfidf_matrix = vectorizer.fit_transform(df['combined_text'])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "top_words_per_cluster = {}\n",
    "for cluster in sorted(df['cluster'].unique()):\n",
    "    cluster_texts = df[df['cluster'] == cluster]['combined_text']\n",
    "    tfidf_matrix_cluster = vectorizer.transform(cluster_texts)\n",
    "    sum_tfidf = tfidf_matrix_cluster.sum(axis=0).A1\n",
    "    top_indices = sum_tfidf.argsort()[-30:][::-1]  \n",
    "    top_words = [(feature_names[i], float(sum_tfidf[i])) for i in top_indices]\n",
    "    top_words_per_cluster[cluster] = top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "376fa4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "for cluster, words in top_words_per_cluster.items():\n",
    "    word_freq = dict(words)\n",
    "    wc = WordCloud(width=600, height=300, background_color='black')\n",
    "    wc.generate_from_frequencies(word_freq)\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Кластер {cluster}: Ключевые слова\", pad=12)\n",
    "    plt.savefig(f\"../plots/cluster_{cluster}_wordcloud.png\", bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0434eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_per_cluster_strkeys = {int(k): v for k, v in top_words_per_cluster.items()}\n",
    "\n",
    "with open('../data/cluster_top_words.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(top_words_per_cluster_strkeys, f, ensure_ascii=False, sort_keys=True, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
